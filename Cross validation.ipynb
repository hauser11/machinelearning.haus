{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting quandl\n",
      "  Downloading https://files.pythonhosted.org/packages/07/ab/8cd479fba8a9b197a43a0d55dd534b066fb8e5a0a04b5c0384cbc5d663aa/Quandl-3.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas>=0.14 in /opt/anaconda3/lib/python3.7/site-packages (from quandl) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.8 in /opt/anaconda3/lib/python3.7/site-packages (from quandl) (1.17.2)\n",
      "Requirement already satisfied: requests>=2.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from quandl) (2.22.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/lib/python3.7/site-packages (from quandl) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.7/site-packages (from quandl) (2.8.0)\n",
      "Collecting inflection>=0.3.1 (from quandl)\n",
      "  Downloading https://files.pythonhosted.org/packages/52/c1/36be286d85dbd76527fb613527222a795d7c071da195fa916e7bf3cb03cb/inflection-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: more-itertools in /opt/anaconda3/lib/python3.7/site-packages (from quandl) (7.2.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.14->quandl) (2019.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->quandl) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->quandl) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->quandl) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.7.0->quandl) (1.24.2)\n",
      "Installing collected packages: inflection, quandl\n",
      "Successfully installed inflection-0.4.0 quandl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install quandl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/lib/python3.7/site-packages (0.21.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /opt/anaconda3/lib/python3.7/site-packages (from scikit-learn) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97 (+/- 0.09)\n",
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n",
      "\n",
      "[2 3] [0 1]\n",
      "[0 1] [2 3]\n",
      "[0 2] [1 3]\n",
      "[1 3] [0 2]\n",
      "one variable used for testing\n",
      "[1 2 3] [0]\n",
      "[0 2 3] [1]\n",
      "[0 1 3] [2]\n",
      "[0 1 2] [3]\n",
      "removing p samples\n",
      "[2 3] [0 1]\n",
      "[1 3] [0 2]\n",
      "[1 2] [0 3]\n",
      "[0 3] [1 2]\n",
      "[0 2] [1 3]\n",
      "[0 1] [2 3]\n",
      "shuffle and split\n",
      "[9 1 6 7 3 0 5] [2 8 4]\n",
      "[2 9 8 0 6 7 4] [3 5 1]\n",
      "[4 5 1 0 6 9 7] [2 3 8]\n",
      "[2 7 5 8 0 3 4] [6 1 9]\n",
      "[4 1 0 6 8 9 3] [5 2 7]\n",
      "same percentage of samples of each target class as the complete set\n",
      "train - [30  3]  | test _ [15  2]\n",
      "train - [30  3]  | test _ [15  2]\n",
      "train - [30  4]  | test _ [15  1]\n",
      "train - [28  5]  | test - [17]\n",
      "train - [28  5]  | test - [17]\n",
      "train - [34]  | test - [11  5]\n",
      "ensures the same group is not represented in both testing and training sets\n",
      "prevents overfitting due to person specific data\n",
      "[0 1 2 3 4 5] [6 7 8 9]\n",
      "[0 1 2 6 7 8 9] [3 4 5]\n",
      "[3 4 5 6 7 8 9] [0 1 2]\n",
      "cross validation based on different experiments\n",
      "training set of all samples of the experiment except one\n",
      "[2 3 4 5 6] [0 1]\n",
      "[0 1 4 5 6] [2 3]\n",
      "[0 1 2 3] [4 5 6]\n",
      "removes P groups for each training/test set\n",
      "[4 5] [0 1 2 3]\n",
      "[2 3] [0 1 4 5]\n",
      "[0 1] [2 3 4 5]\n",
      " Group Shuffle Split generates a sequence of randomize partitions\n",
      "subset of groups are held out for each split\n",
      "[0 1 2 3] [4 5 6 7]\n",
      "[2 3 6 7] [0 1 4 5]\n",
      "[2 3 4 5] [0 1 6 7]\n",
      "[4 5 6 7] [0 1 2 3]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X.shape, y.shape\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "X_train.shape, y_train.shape\n",
    "X_test.shape, y_test.shape\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "scores = cross_val_score(clf, X, y, cv = 10)\n",
    "scores\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() *2))\n",
    "\n",
    "scores = cross_val_score(\n",
    "    clf, X, y, cv=5, scoring='f1_macro')\n",
    "\n",
    "scores\n",
    "\n",
    "n_samples = X.shape[0]\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=0)\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "\n",
    "\n",
    "def custom_cv_2folds(X):\n",
    "    n= X.shape[0]\n",
    "    i=1\n",
    "    while i<=2:\n",
    "        idx = np.arange(n * (i-1) / 2, n * i / 2, dtype=int)\n",
    "        yield idx, idx\n",
    "        i += 1\n",
    "        \n",
    "custom_cv = custom_cv_2folds(X)\n",
    "cross_val_score(clf, X, y, cv=custom_cv)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.4, random_state=0)\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_transformed = scaler.transform(X_train)\n",
    "clf = svm.SVC(C=1).fit(X_train_transformed, y_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "clf.score(X_test_transformed, y_test)\n",
    "\n",
    "clf = make_pipeline(preprocessing.StandardScaler(), svm.SVC(C=1))\n",
    "cross_val_score(clf, X, y, cv=cv)\n",
    "\n",
    "\n",
    "scoring = ['precision_macro', 'recall_macro']\n",
    "clf = svm.SVC(kernel='linear', C=1, random_state=0)\n",
    "scores = cross_validate(clf, X, y, scoring=scoring)\n",
    "sorted(scores.keys())\n",
    "scores['test_recall_macro']\n",
    "\n",
    "scoring = {'prec_macro': 'precision_macro',\n",
    "          'rec_macro': make_scorer(recall_score, average='macro')}\n",
    "scores = cross_validate(clf, X, y, scoring=scoring,\n",
    "                       cv=5, return_train_score=True)\n",
    "sorted(scores.keys())\n",
    "scores['train_rec_macro']\n",
    "\n",
    "\n",
    "scores = cross_validate(clf, X, y,\n",
    "                       scoring='precision_macro', cv= 10,\n",
    "                       return_estimator=True)\n",
    "sorted(scores.keys())\n",
    "\n",
    "X = [\"a\", \"b\", \"c\", \"d\"]\n",
    "kf = KFold(n_splits=2)\n",
    "for train, test in kf.split(X):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    \n",
    "X = np.array([[0., 0.], [1., 1.], [-1., -1.], [2., 2.]])\n",
    "y = np.array([0, 1, 0, 1])\n",
    "X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "random_state = 12883823\n",
    "rkf = RepeatedKFold(n_splits= 2, n_repeats=2, random_state=random_state)\n",
    "for train, test in rkf.split(X):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "\n",
    "print(\"one variable used for testing\")\n",
    "X = [1,2,3,4]\n",
    "loo=LeaveOneOut()\n",
    "for train, test in loo.split(X):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    \n",
    "print(\"removing p samples\")    \n",
    "X = np.ones(4)\n",
    "lpo = LeavePOut(p=2)\n",
    "for train, test in lpo.split(X):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    \n",
    "print(\"shuffle and split\")    \n",
    "X = np.arange(10)\n",
    "ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)\n",
    "for train_index, test_index in ss.split(X):\n",
    "    print(\"%s %s\" % (train_index, test_index))\n",
    "    \n",
    "print(\"same percentage of samples of each target class as the complete set\")\n",
    "X, y = np.ones((50, 1)), np.hstack(([0] * 45, [1] * 5))\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "for train, test in skf.split(X, y):\n",
    "    print('train - {}  | test _ {}'.format(\n",
    "    np.bincount(y[train]), np.bincount(y[test])))\n",
    "    \n",
    "kf = KFold(n_splits=3)\n",
    "for train, test in kf.split(X, y):\n",
    "    print('train - {}  | test - {}'.format(\n",
    "    np.bincount(y[train]), np.bincount(y[test])))\n",
    "    \n",
    "    \n",
    "print(\"ensures the same group is not represented in both testing and training sets\")\n",
    "print(\"prevents overfitting due to person specific data\")\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
    "groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "for train, test in gkf.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train,test))\n",
    "    \n",
    "print(\"cross validation based on different experiments\")\n",
    "print(\"training set of all samples of the experiment except one\")\n",
    "\n",
    "X = [1,5,10, 50, 60, 70, 80]\n",
    "y=[0,1,1,2,2,2,2]\n",
    "groups = [1, 1, 2, 2, 3, 3, 3]\n",
    "logo = LeaveOneGroupOut()\n",
    "for train, test in logo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "print(\"removes P groups for each training/test set\")\n",
    "\n",
    "X = np.arange(6)\n",
    "y = [1, 1, 1, 2, 2, 2]\n",
    "groups = [1, 1, 2, 2, 3, 3]\n",
    "lpgo = LeavePGroupsOut(n_groups = 2)\n",
    "for train, test in lpgo.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    \n",
    "print(\" Group Shuffle Split generates a sequence of randomize partitions\")\n",
    "print('subset of groups are held out for each split')\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 0.001]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"a\"]\n",
    "groups = [1, 1, 2, 2, 3, 3, 4, 4]\n",
    "gss = GroupShuffleSplit(n_splits=4, test_size=0.5, random_state=0)\n",
    "for train, test in gss.split(X,y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "  \n",
    "\n",
    "print(\"variation of k-fold which returns first k folds as train set\")\n",
    "print(\"and k+1th fold as test set\")\n",
    "X = np.array([[1,2], [3,4], [1,2], [3,4], [1, 2], [3, 4]])\n",
    "y = np.array ([1,2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "print(tscv)\n",
    "for train, test in tscv.split(X):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90, 4), (90,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
